<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tri Chi Playground</title>
    <script src="coi-serviceworker.min.js"></script>
</head>
<body>
<div class="container">
    <canvas id="canvas" style="width: 99%; height: 99%; position: absolute"></canvas>
    <div id="ui" style="position: absolute; right: 0; z-index: 1;"></div>
</div>

<script type="module">
    import * as Comlink from "https://unpkg.com/comlink/dist/esm/comlink.mjs";

    import {vec3n, mat4n} from 'https://wgpu-matrix.org/dist/3.x/wgpu-matrix.module.min.js';
    import {FPSCameraController} from './fps-camera.js';
    import {makeUi} from './ui.js';
    import {webgpuNotSupported} from './util.js';
    import {makeClusterRenderer} from './cluster-renderer.js';

    const urlParams = new URLSearchParams(window.location.search);
    const useTimestampQuery = urlParams.has('timestamp_query');

    const trichiWorker = Comlink.wrap(new Worker('trichi-worker.js', {type: 'module'}));

    async function main() {
        if (!('gpu' in navigator)) {
            webgpuNotSupported();
            return;
        }
        const adapter = await navigator.gpu.requestAdapter();
        if (!adapter) {
            webgpuNotSupported();
            return;
        }
        console.info('Available adapter features', [...adapter.features]);

        const deviceFeatures = [];
        if (useTimestampQuery && adapter.features.has('timestamp-query')) {
            deviceFeatures.push('timestamp-query');
        }

        const device = await adapter.requestDevice({requiredFeatures: deviceFeatures});
        console.info('Enabled device features', [...device.features]);

        const canvas = document.querySelector('canvas');
        const resolution = [canvas.clientWidth, canvas.clientHeight].map(s => s * window.devicePixelRatio);
        canvas.width = resolution[0];
        canvas.height = resolution[1];

        if (device.features.has('timestamp-query')) {
            // todo: timings
        }

        const context = canvas.getContext('webgpu');
        const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
        context.configure({
            device,
            format: presentationFormat,
        });

        const cameraController = new FPSCameraController(canvas);

        const fovRad = 45.0 * (Math.PI / 180.0);
        const projection = mat4n.perspectiveReverseZ(
            fovRad,
            resolution[0] / resolution[1],
            1.0,
        );

        const backBuffer = device.createTexture({
            size: resolution,
            format: 'rgba16float',
            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
        });
        const backBufferView = backBuffer.createView();

        const depthBuffer = device.createTexture({
            size: resolution,
            format: 'depth24plus',
            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
        });
        const depthBufferView = depthBuffer.createView();

        function makePipeline() {
            const module = device.createShaderModule({
                code: `
                    @group(0) @binding(0) var backbuffer: texture_2d<f32>;

                    @vertex
                    fn vertex(@builtin(vertex_index) vertex_index: u32) -> @builtin(position) vec4<f32> {
                        return vec4(vec2(f32((vertex_index << 1) & 2), f32(vertex_index & 2)) * 2 - 1, 0, 1);
                    }

                    fn coords_in_rect(coords: vec2<u32>, rect_min: vec2<u32>, rect_max: vec2<u32>) -> bool {
                        return all(coords >= rect_min) && all(coords < rect_max);
                    }

                    @fragment
                    fn fragment(@builtin(position) coord: vec4<f32>) -> @location(0) vec4<f32> {
                        let texture_coords = vec2<u32>(floor(coord.xy));

                        let backbuffer_size = textureDimensions(backbuffer, 0).xy;

                        if coords_in_rect(texture_coords, vec2<u32>(), backbuffer_size) {
                            let rgb = textureLoad(backbuffer, texture_coords, 0).rgb;
                            return vec4(rgb, 1.0);
                        } else {
                            return vec4(0.0, 0.0, 0.0, 1.0);
                        }
                    }
                    `,
            });
            return device.createRenderPipeline({
                label: 'present',
                layout: 'auto',
                vertex: {
                    module,
                },
                fragment: {
                    module,
                    targets: [{format: presentationFormat}],
                },
            });
        }

        const presentPipeline = makePipeline();
        const presentBindGroup = device.createBindGroup({
            label: 'present',
            layout: presentPipeline.getBindGroupLayout(0),
            entries: [
                {
                    binding: 0,
                    resource: backBufferView,
                },
            ],
        });

        const clusterRenderer = makeClusterRenderer(device, backBuffer.format, depthBuffer.format, null, true);

        const resolutionDependentStuff = {
            projection,
            backBuffer,
            backBufferView,
            depthBuffer,
            depthBufferView,
            presentBindGroup,
        };

        // from Nexus
        // https://github.com/cnr-isti-vclab/nexus/blob/ae6bf8601303884250d3c73b9e1d4cbe179f9b92/src/common/frustum.cpp#L49
        const setErrorProjectionParams = _ => {
            const invProj = mat4n.inverse(resolutionDependentStuff.projection);
            const c = vec3n.transformMat4(vec3n.create(0, 0, 1), invProj);
            const s = vec3n.transformMat4(vec3n.create(1, 0, 1), invProj);
            const zNear = vec3n.length(c);
            const side = vec3n.length(vec3n.subtract(s, c));
            resolutionDependentStuff.errorProjectionParams = {
                resolution: (2.0 * side / zNear) / resolution[1],
                zNear,
            };
        };
        setErrorProjectionParams();

        let resizeInProgress = false;
        const handleResize = _ => {
            resolution[0] = canvas.clientWidth * window.devicePixelRatio;
            resolution[1] = canvas.clientHeight * window.devicePixelRatio;

            canvas.width = resolution[0];
            canvas.height = resolution[1];

            resolutionDependentStuff.projection = mat4n.perspectiveReverseZ(
                fovRad,
                resolution[0] / resolution[1],
                1.0,
            );
            resolutionDependentStuff.backBuffer = device.createTexture({
                size: resolution,
                format: 'rgba16float',
                usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
            });
            resolutionDependentStuff.backBufferView = resolutionDependentStuff.backBuffer.createView();
            resolutionDependentStuff.depthBuffer = device.createTexture({
                size: resolution,
                format: 'depth24plus',
                usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
            });
            resolutionDependentStuff.depthBufferView = resolutionDependentStuff.depthBuffer.createView();
            resolutionDependentStuff.presentBindGroup = device.createBindGroup({
                layout: presentPipeline.getBindGroupLayout(0),
                entries: [
                    {
                        binding: 0,
                        resource: resolutionDependentStuff.backBufferView,
                    },
                ],
            });

            setErrorProjectionParams();

            resizeInProgress = false;
        };

        let timeout = false;
        window.addEventListener('resize', _ => {
            resizeInProgress = true;
            clearTimeout(timeout);
            timeout = setTimeout(handleResize, 250);
        });

        let transform = mat4n.identity();
        let radiusScale = 1.0;

        let hasMesh = false;
        let isProcessingModel = false;
        async function processModel(file) {
            console.log(file);
            console.log(trichiWorker);
            await trichiWorker(
                Comlink.transfer(file, [file.bytes.buffer]),
                Comlink.proxy((newMesh, trans, scalingFactor) => {
                    clusterRenderer.newMesh(newMesh);
                    transform = trans;
                    radiusScale = scalingFactor;
                    cameraController.reset({});
                    isProcessingModel = false;
                    hasMesh = true;
                }),
                Comlink.proxy(e => {
                    console.log('failed to process model:', e);
                    isProcessingModel = false;
                }),
            );
        }

        const dropZoneId = 'container';
        ['dragenter', 'dragover', 'drop'].forEach(eventName => {
            window.addEventListener(eventName, e => {
                if (e.target.id !== dropZoneId) {
                    e.preventDefault();
                    if (eventName === 'drop') {
                        e.dataTransfer.dropEffect = 'move';
                        if (isProcessingModel) {
                            console.log('currently processing a model, ignoring dropped file(s)');
                            return;
                        }
                        Promise.all([...e.dataTransfer.items]
                            .filter(i => i.kind === 'file')
                            .map(async f => {
                                const file = f.getAsFile();
                                return { name: file.name, bytes: new Uint8Array(await file.arrayBuffer()) };
                            })
                        ).then(files => {
                            if (files.length === 0) {
                                return;
                            }
                            isProcessingModel = true;

                            if (files.length > 1) {
                                console.log('multiple files dropped, ignoring all but the first one');
                            }
                            console.log('processing', files[0].name);
                            return processModel(files[0]);
                        });
                    }
                }
            }, false);
        });

        const params = makeUi();

        let lastTime = new Date();
        let frameId = 0;
        const render = () => {
            const now = new Date();
            const dt = (now - lastTime);
            lastTime = now;

            ++frameId;

            if (resizeInProgress) {
                setTimeout(render, 250);
                return;
            }

            cameraController.update(dt);

            const cameraView = cameraController.view;
            clusterRenderer.update(
                {
                    view: cameraView,
                    projection: resolutionDependentStuff.projection,
                    position: cameraController.position,
                },
                {instances: [transform]},
                {
                    ...resolutionDependentStuff.errorProjectionParams,
                    threshold: params.renderSettings.errorThreshold,
                    radiusScale
                },
                {
                    renderMode: params.renderSettings.renderMode === 'triangleId' ? 1 : 0,
                },
                params.renderSettings.updateCullingCamera,
            );

            const encoder = device.createCommandEncoder();

            if (hasMesh) {
                clusterRenderer.encodeIndirect(
                    encoder,
                    resolutionDependentStuff.backBufferView,
                    resolutionDependentStuff.depthBufferView,
                );
            }

            const pass = encoder.beginRenderPass({
                colorAttachments: [{
                    view: context.getCurrentTexture().createView(),
                    clearValue: [0, 0, 0, 1],
                    loadOp: 'clear',
                    storeOp: 'store',
                }],
            });
            pass.setPipeline(presentPipeline);
            pass.setBindGroup(0, resolutionDependentStuff.presentBindGroup);
            pass.draw(3);
            pass.end();

            device.queue.submit([encoder.finish()]);

            requestAnimationFrame(render);
        };
        render();
    }

    main();
</script>
</body>
</html>
